{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a365dc",
   "metadata": {},
   "source": [
    "## Triton 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e886e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "from torch import Tensor\n",
    "import triton.language as tl\n",
    "import jaxtyping\n",
    "from jaxtyping import Float32, Int32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bae7e9",
   "metadata": {},
   "source": [
    "### Load and Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff68cf",
   "metadata": {},
   "source": [
    "#### 1D Load & Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31f06310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2., 1., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch, triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.jit\n",
    "def add_one_to_five_elements(x_ptr):\n",
    "    # triton에서는 CUDA와 달리 thread index를 직접 다루지 않음\n",
    "    # 대신 arange를 이용해 벡터 연산으로 표현하면 이것이 thread에 매핑됨\n",
    "    offset = tl.arange(0, 8) # arange는 반드시 2의 거듭제곱 형태 tensor만 가능.\n",
    "    x = tl.load(x_ptr + offset, mask=offset < 5, other=0) # other는 mask에 해당하지 않는 경우 사용되는 default값\n",
    "    tl.store(x_ptr + offset, x+1, mask=offset < 5)\n",
    "\n",
    "# 텐서 생성\n",
    "x = torch.ones(8, device='cuda', dtype=torch.float32)\n",
    "\n",
    "# 커널 실행\n",
    "add_one_to_five_elements[(1, 1, 1)](x) # grid가 (1, 1, 1) \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e5370",
   "metadata": {},
   "source": [
    "#### 2D Load & Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4081074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 1., 1., 1., 1., 1.],\n",
      "        [2., 2., 2., 1., 1., 1., 1., 1.],\n",
      "        [2., 2., 2., 1., 1., 1., 1., 1.],\n",
      "        [2., 2., 2., 1., 1., 1., 1., 1.],\n",
      "        [2., 2., 2., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "@triton.jit\n",
    "def add_one_to_5x3_elements(x_ptr):\n",
    "    # 2차원 index는 이렇게 생성\n",
    "    offset_x = tl.arange(0, 8)[:, None]\n",
    "    offset_y = tl.arange(0, 8)[None, :]\n",
    "    offset = offset_x * 8 + offset_y\n",
    "\n",
    "    x = tl.load(\n",
    "        x_ptr + offset, \n",
    "        mask=(offset_x < 5) & (offset_y < 3))\n",
    "    tl.store(\n",
    "        x_ptr + offset, \n",
    "        x+1, \n",
    "        mask=(offset_x < 5) & (offset_y < 3))\n",
    "\n",
    "# 2D 텐서 생성\n",
    "x = torch.ones((8, 8), device='cuda', dtype=torch.float32)\n",
    "\n",
    "# 커널 실행\n",
    "add_one_to_5x3_elements[(1, 1, 1)](x) # grid가 (1, 1, 1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e4773",
   "metadata": {},
   "source": [
    "### 여러 개의 Block 사용하기\n",
    "큰 tensor를 다룰 때에는 여러 개의 block을 사용해야 함.\n",
    "kernel 호출 시 grid size를 명시해주고, grid 내의 위치를 `tl.program_id`로 가져오면 됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fa84495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "@triton.jit\n",
    "def long_vector_add(x_ptr, y_ptr, z_ptr, N: tl.constexpr, BLOCK_SIZE: tl.constexpr):\n",
    "    pid = tl.program_id(0)  # CUDA의 BlockIdx와 유사\n",
    "    offset = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offset < N\n",
    "    x = tl.load(x_ptr + offset, mask=mask)\n",
    "    y = tl.load(y_ptr + offset, mask=mask)\n",
    "    z = x + y\n",
    "    tl.store(z_ptr + offset, z, mask=mask)  \n",
    "\n",
    "N = 2048  \n",
    "a = torch.randn(N, device='cuda', dtype=torch.float32)\n",
    "b = torch.randn(N, device='cuda', dtype=torch.float32)\n",
    "c = torch.zeros(N, device='cuda', dtype=torch.float32)\n",
    "# 커널 실행\n",
    "BLOCK_SIZE = 128\n",
    "long_vector_add[((N + BLOCK_SIZE - 1) // BLOCK_SIZE, 1, 1)](a, b, c, N, BLOCK_SIZE) # grid가 (1, 1, 1) \n",
    "# print(c)\n",
    "\n",
    "if (c.cpu() - (a + b).cpu()).abs().max() < 1e-7:\n",
    "    print(\"Correct!\")\n",
    "else:\n",
    "    print(\"Incorrect!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6bcf55",
   "metadata": {},
   "source": [
    "## Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef18d9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Correct!\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "@triton.jit\n",
    "def matmul_kernel(\n",
    "    a_ptr, b_ptr, c_ptr, \n",
    "    M: tl.constexpr, N: tl.constexpr, K: tl.constexpr,\n",
    "    BLOCKSIZE_M: tl.constexpr, BLOCKSIZE_N: tl.constexpr, BLOCKSIZE_K: tl.constexpr):\n",
    "    \n",
    "    pid_m, pid_n = tl.program_id(0), tl.program_id(1)\n",
    "    # A[pid_m * BLOCK_SIZE_M: (pid_m + 1) * BLOCK_SIZE_M, :]와 B [:, pid_n * BLOCK_SIZE_N: (pid_n + 1) * BLOCK_SIZE_N]을 곱하기\n",
    "    \n",
    "    offset_m = pid_m * BLOCKSIZE_M + tl.arange(0, BLOCKSIZE_M)\n",
    "    offset_n = pid_n * BLOCKSIZE_N + tl.arange(0, BLOCKSIZE_N)\n",
    "     \n",
    "    acc = tl.zeros((BLOCKSIZE_M, BLOCKSIZE_N), dtype=tl.float32)\n",
    "\n",
    "    for k in range(0, K, BLOCKSIZE_K):\n",
    "        offset_k = k + tl.arange(0, BLOCKSIZE_K)\n",
    "\n",
    "        a = tl.load(\n",
    "            a_ptr + offset_m[:, None] * K + offset_k[None, :], \n",
    "            mask=(offset_m[:, None] < M) & (offset_k[None, :] < K),\n",
    "            other=0.0)\n",
    "        b = tl.load(\n",
    "            b_ptr + offset_k[:, None] * N + offset_n[None, :],\n",
    "            mask=(offset_k[:, None] < K) & (offset_n[None, :] < N),\n",
    "            other=0.0)\n",
    "\n",
    "        acc += tl.dot(a, b, allow_tf32=False)   # TF32를 허용하면 정밀도가 떨어짐\n",
    "\n",
    "    tl.store(\n",
    "        c_ptr + offset_m[:, None] * N + offset_n[None, :],\n",
    "        acc,\n",
    "        mask=(offset_m[:, None] < M) & (offset_n[None, :] < N),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "BLOCKSIZE_M = 64\n",
    "BLOCKSIZE_N = 64\n",
    "BLOCKSIZE_K = 64 \n",
    "\n",
    "sizes = [(120, 32, 30), (1000, 711, 400), (30, 63, 50)]\n",
    "\n",
    "for m, k, n in sizes:\n",
    "    A = torch.randn(m, k).cuda()\n",
    "    B = torch.randn(k, n).cuda()\n",
    "    C = torch.zeros(m, n).cuda()\n",
    "\n",
    "    # kernel call\n",
    "    grid = ((m + BLOCKSIZE_M - 1) // BLOCKSIZE_M, (n + BLOCKSIZE_N - 1) // BLOCKSIZE_N, 1)\n",
    "    matmul_kernel[grid](A, B, C, m, n, k, BLOCKSIZE_M, BLOCKSIZE_N, BLOCKSIZE_K)\n",
    "    \n",
    "    error = (A@B - C).abs().mean()\n",
    "    if error < 1e-5:\n",
    "        print(\"Correct!\")\n",
    "    else:\n",
    "        print(f\"Incorrect! error: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deac587",
   "metadata": {},
   "source": [
    "### FlashAttention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
